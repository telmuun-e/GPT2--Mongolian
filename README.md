# GPT2--Mongolian

Mongolian GPT-2 model. Perplexity loss is 1.53. 

Training data: 600MB. Crawled from mn.wikipedia.com, ikon.mn, dnn.mn

![alt text](https://github.com/telmuun-e/GPT2--Mongolian/blob/main/data/ppl_loss.png?raw=true)

### Sample
![alt text](https://github.com/telmuun-e/GPT2--Mongolian/blob/main/data/sample_front.png?raw=true)
